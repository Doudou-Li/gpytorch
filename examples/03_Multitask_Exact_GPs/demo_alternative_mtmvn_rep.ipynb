{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative representation of MultitaskMultivariateNormal\n",
    "\n",
    "## Issue:\n",
    "Currently, the interleaved/non-interleaved representation of MTMVN creates a bunch of headaches. It would be nice to have a higher-level API that abstracts away from these details. \n",
    "\n",
    "\n",
    "## Suggestion:\n",
    "Represent the covariance matrix as an \"unrolled\" tensor (e.g. `n x n x m x m`), instead of a `nm x nm` covariance matrix. That way things like scalarizations are easily done, and reshaping/viewing/getting items can be done more straightforwardly. \n",
    "\n",
    "\n",
    "## Challenge:\n",
    "In order to sample from this MVN, we need to compute the full `nm x nm` covariance matrix (to either compute the cholesky decomposition or apply iterative approximate root decomposition methods. We need to make sure this is transparent, fast, and happens without much overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 3  # number of points\n",
    "m = 2  # number of outputs\n",
    "\n",
    "# create some full covar\n",
    "\n",
    "def make_rand_covar(k, batch_shape=torch.Size()):\n",
    "    a = torch.rand(*batch_shape, k, k)\n",
    "    return a @ a.transpose(-1, -2) + torch.diag_embed(torch.rand(k))\n",
    "    \n",
    "A = make_rand_covar(n * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interleaved: block matrix where each block is an intra-point, cross-task covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_inter = torch.zeros(n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for i_ in range(n):\n",
    "        for j in range(m):\n",
    "            for j_ in range(m):\n",
    "                C_inter[i, i_, j, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can construct the full matrix as follows:\n",
    "C_inter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "         [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "         [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "         [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "         [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "         [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]],\n",
       "\n",
       "        [[3.7497, 2.9997, 3.5260, 2.8324, 2.0587, 2.5959],\n",
       "         [2.9997, 3.3089, 3.5956, 2.2006, 1.9716, 2.3898],\n",
       "         [3.5260, 3.5956, 4.9785, 2.4866, 2.2309, 2.7182],\n",
       "         [2.8324, 2.2006, 2.4866, 2.8368, 1.6344, 2.1747],\n",
       "         [2.0587, 1.9716, 2.2309, 1.6344, 2.4897, 1.7867],\n",
       "         [2.5959, 2.3898, 2.7182, 2.1747, 1.7867, 2.8870]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "b = 2\n",
    "A_b = torch.stack([A, A + 1])\n",
    "C_inter_b = torch.zeros(b, n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for i_ in range(n):\n",
    "            for j in range(m):\n",
    "                for j_ in range(m):\n",
    "                    C_inter_b[b_, i, i_, j, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "                    \n",
    "C_inter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "         [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "         [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "         [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "         [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "         [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]],\n",
       "\n",
       "        [[3.7497, 2.9997, 3.5260, 2.8324, 2.0587, 2.5959],\n",
       "         [2.9997, 3.3089, 3.5956, 2.2006, 1.9716, 2.3898],\n",
       "         [3.5260, 3.5956, 4.9785, 2.4866, 2.2309, 2.7182],\n",
       "         [2.8324, 2.2006, 2.4866, 2.8368, 1.6344, 2.1747],\n",
       "         [2.0587, 1.9716, 2.2309, 1.6344, 2.4897, 1.7867],\n",
       "         [2.5959, 2.3898, 2.7182, 2.1747, 1.7867, 2.8870]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the general formulation:\n",
    "batch_shape = C_inter_b.shape[:-4]\n",
    "C_inter_b.permute(*range(len(batch_shape)), -4, -2, -3, -1).reshape(*batch_shape, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we go back? I.e. construct C_inter efficiently form the full matrix? Just do the same thing in reverse\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_inter_b_recov = A_b.reshape(*batch_shape, n, m, n, m).permute(*range(len(batch_shape)), -4, -2, -3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(C_inter_b, C_inter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-interleaved: block matrix where each block is an intra-task, cross-point covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_noninter = torch.zeros(m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(m):\n",
    "    for i_ in range(m):\n",
    "        for j in range(n):\n",
    "            for j_ in range(n):\n",
    "                C_noninter[i, i_, j, j_] = A[i*n+j, i_*n+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again we can construct the matrix as follows:\n",
    "C_noninter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "C_noninter_b = torch.zeros(b, m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(m):\n",
    "        for i_ in range(m):\n",
    "            for j in range(n):\n",
    "                for j_ in range(n):\n",
    "                    C_noninter_b[b_, i, i_, j, j_] = A_b[b_, i*n+j, i_*n+j_]\n",
    "                    \n",
    "torch.allclose(\n",
    "    C_noninter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and again we can go back the same way\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_noninter_b_recov = A_b.reshape(*batch_shape, m, n, m, n).permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_noninter_b, C_noninter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternate mixed-interleaved: block matrix where each block is an intra-point, cross-task covariance\n",
    "\n",
    "This seems to be the most useful internal representation, as this means we don't have to do any permuting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate representation\n",
    "C_alt = torch.zeros(n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        for i_ in range(n):    \n",
    "            for j_ in range(m):\n",
    "                C_alt[i, j, i_, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7497, 1.9997, 2.5260, 1.8324, 1.0587, 1.5959],\n",
       "        [1.9997, 2.3089, 2.5956, 1.2006, 0.9716, 1.3898],\n",
       "        [2.5260, 2.5956, 3.9785, 1.4866, 1.2309, 1.7182],\n",
       "        [1.8324, 1.2006, 1.4866, 1.8368, 0.6344, 1.1747],\n",
       "        [1.0587, 0.9716, 1.2309, 0.6344, 1.4897, 0.7867],\n",
       "        [1.5959, 1.3898, 1.7182, 1.1747, 0.7867, 1.8870]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is super straightforward\n",
    "C_alt.view(n*m, n*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate representation\n",
    "C_alt_b = torch.zeros(b, n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            for i_ in range(n):    \n",
    "                for j_ in range(m):\n",
    "                    C_alt_b[b_, i, j, i_, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "\n",
    "batch_shape = C_alt_b.shape[:-4]\n",
    "torch.allclose(\n",
    "    C_alt_b.view(*batch_shape, n*m, n*m),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ....and going back\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_alt_b_recov = A_b.reshape(*batch_shape, n, m, n, m) #.permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_alt_b, C_alt_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What if the tensor memory layout is different? Do we need to handle that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalarizing\n",
    "\n",
    "This representation makes scalarizing across the outputs trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7856, 0.6805, 0.4484],\n",
       "        [0.6805, 0.7218, 0.4162],\n",
       "        [0.4484, 0.4162, 0.4479]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(m)\n",
    "(C_alt @ weights).transpose(-1, -2) @ weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing independet outputs\n",
    "\n",
    "Here we can just store the `m` individual `n x n` blocks as a `m x n x n` tensor, no need to store the cross covariances.\n",
    "\n",
    "We could also think of the case where we have independence across points, and only inter-task correlation. This will typically not be the case though, so we can punt on this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7513, 0.2001, 0.3947, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2001, 1.3723, 0.1992, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3947, 0.1992, 1.4604, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 1.0000, 0.7192, 0.7787],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7192, 1.9332, 1.2580],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7787, 1.2580, 1.5258]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.lazy import BlockDiagLazyTensor\n",
    "\n",
    "C_indep = torch.stack([make_rand_covar(n) for _ in range(m)])\n",
    "\n",
    "# using the lazy here will speed up matrix operations\n",
    "BlockDiagLazyTensor(C_indep).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7513, 0.2001, 0.3947],\n",
       "         [0.2001, 1.3723, 0.1992],\n",
       "         [0.3947, 0.1992, 1.4604]],\n",
       "\n",
       "        [[1.0000, 0.7192, 0.7787],\n",
       "         [0.7192, 1.9332, 1.2580],\n",
       "         [0.7787, 1.2580, 1.5258]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7513, 0.2001, 0.3947, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2001, 1.3723, 0.1992, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3947, 0.1992, 1.4604, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 1.0000, 0.7192, 0.7787],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7192, 1.9332, 1.2580],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7787, 1.2580, 1.5258]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we construct the full matrix (we don't want to do this in general, but maybe sometimes)\n",
    "# Once https://github.com/pytorch/pytorch/issues/31932 goes in, we can just use that instead\n",
    "\n",
    "batch_shape = C_indep.shape[:-3]\n",
    "out = torch.zeros(*batch_shape, m*n, m*n, device=C_indep.device, dtype=C_indep.dtype)\n",
    "for i, vals in enumerate(C_indep):\n",
    "    start = i*n\n",
    "    end = start + n\n",
    "    out[..., start:end, start:end].copy_(vals)\n",
    "    \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also allow arbitrary order in the construction...\n",
    "\n",
    "### ... so long as we have a consistent internal representation\n",
    "\n",
    "The following orders are admissible (`n` is the number of points, `t` is the number tasks):\n",
    "\n",
    "```\n",
    "nntt\n",
    "ntnt\n",
    "nttn\n",
    "ttnn\n",
    "tntn\n",
    "tnnt\n",
    "\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "So basically we have the set \n",
    "```\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "and then the whole set of admissible combinations we get by combining this wiht the set we get by post-pending with the single letter (we could pre-pend too but that would just generate duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know this is admissible. We'd like to store things consistently internally. There are four options:\n",
    "\n",
    "- no independence -> can standardize to `n x t x n x t`\n",
    "- cross-task independence only -> can standardize to `t x n x n`\n",
    "- cross-point independence only -> can standardize to `n x t x t`\n",
    "- cross-task AND cross-point independence: This is trivial -> can standardize to `n x t` (just marginal variances)\n",
    "\n",
    "**For now we focus on the first two cases**, we can deal with the other ones later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions.new_multitask_multivariate_normal import MultitaskMultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_b = torch.randn(b, n, m)\n",
    "\n",
    "mtmvn = MultitaskMultivariateNormal(mean=mean_b, covariance=C_alt_b, order=(\"n\" ,\"t\", \"n\", \"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.1266, -28.4039])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.log_prob(mtmvn.mean + torch.randn_like(mtmvn.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_indep_b = torch.stack([C_indep, C_indep + 1])\n",
    "\n",
    "mtmvn_indep = MultitaskMultivariateNormal(mean=mean_b, covariance=C_indep_b, order=(\"t\", \"n\", \"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -7.5314, -11.0381])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.log_prob(mtmvn_indep.mean + torch.randn_like(mtmvn_indep.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronecker product structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.lazy import KroneckerProductLazyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = torch.Size([2])\n",
    "\n",
    "Kn = make_rand_covar(n, batch_shape)\n",
    "Km = make_rand_covar(m, batch_shape)\n",
    "\n",
    "covar = KroneckerProductLazyTensor(Km, Kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2282, 0.2174, 0.5029],\n",
       "         [0.2174, 0.8848, 0.4578],\n",
       "         [0.5029, 0.4578, 1.3140]],\n",
       "\n",
       "        [[2.1553, 1.2025, 0.7948],\n",
       "         [1.2025, 1.7784, 0.6121],\n",
       "         [0.7948, 0.6121, 1.5613]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5423, 0.1257],\n",
       "         [0.1257, 0.9608]],\n",
       "\n",
       "        [[0.8937, 0.7911],\n",
       "         [0.7911, 2.2355]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6661, 0.1179, 0.2727, 0.1544, 0.0273, 0.0632],\n",
       "         [0.1179, 0.4798, 0.2483, 0.0273, 0.1113, 0.0576],\n",
       "         [0.2727, 0.2483, 0.7125, 0.0632, 0.0576, 0.1652],\n",
       "         [0.1544, 0.0273, 0.0632, 1.1801, 0.2089, 0.4832],\n",
       "         [0.0273, 0.1113, 0.0576, 0.2089, 0.8501, 0.4399],\n",
       "         [0.0632, 0.0576, 0.1652, 0.4832, 0.4399, 1.2624]],\n",
       "\n",
       "        [[1.9263, 1.0747, 0.7104, 1.7050, 0.9513, 0.6287],\n",
       "         [1.0747, 1.5894, 0.5471, 0.9513, 1.4068, 0.4842],\n",
       "         [0.7104, 0.5471, 1.3954, 0.6287, 0.4842, 1.2351],\n",
       "         [1.7050, 0.9513, 0.6287, 4.8183, 2.6882, 1.7768],\n",
       "         [0.9513, 1.4068, 0.4842, 2.6882, 3.9756, 1.3684],\n",
       "         [0.6287, 0.4842, 1.2351, 1.7768, 1.3684, 3.4904]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6661, 0.1179, 0.2727, 0.1544, 0.0273, 0.0632],\n",
       "         [0.1179, 0.4798, 0.2483, 0.0273, 0.1113, 0.0576],\n",
       "         [0.2727, 0.2483, 0.7125, 0.0632, 0.0576, 0.1652],\n",
       "         [0.1544, 0.0273, 0.0632, 1.1801, 0.2089, 0.4832],\n",
       "         [0.0273, 0.1113, 0.0576, 0.2089, 0.8501, 0.4399],\n",
       "         [0.0632, 0.0576, 0.1652, 0.4832, 0.4399, 1.2624]],\n",
       "\n",
       "        [[1.9263, 1.0747, 0.7104, 1.7050, 0.9513, 0.6287],\n",
       "         [1.0747, 1.5894, 0.5471, 0.9513, 1.4068, 0.4842],\n",
       "         [0.7104, 0.5471, 1.3954, 0.6287, 0.4842, 1.2351],\n",
       "         [1.7050, 0.9513, 0.6287, 4.8183, 2.6882, 1.7768],\n",
       "         [0.9513, 1.4068, 0.4842, 2.6882, 3.9756, 1.3684],\n",
       "         [0.6287, 0.4842, 1.2351, 1.7768, 1.3684, 3.4904]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can construct the full tensor from the kronecker product (we DON'T want to do this)\n",
    "\n",
    "Dense = Km.unsqueeze(-1).unsqueeze(-1) * Kn.unsqueeze(-3).unsqueeze(-3).expand(*Km.shape, *Kn.shape[-2:])\n",
    "Dense.permute(0, 1, 3, 2, 4).reshape(*Km.shape[:-2], m*n, m*n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
