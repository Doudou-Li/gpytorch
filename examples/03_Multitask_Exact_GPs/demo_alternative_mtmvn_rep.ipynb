{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative representation of MultitaskMultivariateNormal\n",
    "\n",
    "## Issue:\n",
    "Currently, the interleaved/non-interleaved representation of MTMVN creates a bunch of headaches. It would be nice to have a higher-level API that abstracts away from these details. \n",
    "\n",
    "\n",
    "## Suggestion:\n",
    "Represent the covariance matrix as an \"unrolled\" tensor (e.g. `n x n x m x m`), instead of a `nm x nm` covariance matrix. That way things like scalarizations are easily done, and reshaping/viewing/getting items can be done more straightforwardly. \n",
    "\n",
    "\n",
    "## Challenge:\n",
    "In order to sample from this MVN, we need to compute the full `nm x nm` covariance matrix (to either compute the cholesky decomposition or apply iterative approximate root decomposition methods. We need to make sure this is transparent, fast, and happens without much overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 3  # number of points\n",
    "m = 2  # number of outputs\n",
    "\n",
    "# create some full covar\n",
    "\n",
    "def make_rand_covar(k, batch_shape=torch.Size()):\n",
    "    a = torch.rand(*batch_shape, k, k)\n",
    "    return a @ a.transpose(-1, -2) + torch.diag_embed(torch.rand(k))\n",
    "    \n",
    "A = make_rand_covar(n * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interleaved: block matrix where each block is an intra-point, cross-task covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_inter = torch.zeros(n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for i_ in range(n):\n",
    "        for j in range(m):\n",
    "            for j_ in range(m):\n",
    "                C_inter[i, i_, j, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8296, 0.7429, 0.5221, 1.0727, 0.6583, 1.2720],\n",
       "        [0.7429, 2.8304, 0.8278, 1.6706, 1.8234, 1.8707],\n",
       "        [0.5221, 0.8278, 1.8112, 0.6711, 0.7029, 1.0244],\n",
       "        [1.0727, 1.6706, 0.6711, 2.8601, 1.8187, 1.9545],\n",
       "        [0.6583, 1.8234, 0.7029, 1.8187, 2.2391, 1.7424],\n",
       "        [1.2720, 1.8707, 1.0244, 1.9545, 1.7424, 3.4549]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "        [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "        [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "        [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "        [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "        [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can construct the full matrix as follows:\n",
    "C_inter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "         [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "         [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "         [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "         [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "         [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]],\n",
       "\n",
       "        [[3.2407, 2.1343, 2.0139, 2.4896, 2.4506, 2.1681],\n",
       "         [2.1343, 2.7848, 2.1197, 2.4541, 2.7069, 1.9432],\n",
       "         [2.0139, 2.1197, 2.5502, 2.4861, 2.6303, 2.1749],\n",
       "         [2.4896, 2.4541, 2.4861, 4.1754, 3.1889, 2.8183],\n",
       "         [2.4506, 2.7069, 2.6303, 3.1889, 3.7358, 2.4337],\n",
       "         [2.1681, 1.9432, 2.1749, 2.8183, 2.4337, 2.9787]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "b = 2\n",
    "A_b = torch.stack([A, A + 1])\n",
    "C_inter_b = torch.zeros(b, n, n, m, m)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for i_ in range(n):\n",
    "            for j in range(m):\n",
    "                for j_ in range(m):\n",
    "                    C_inter_b[b_, i, i_, j, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "                    \n",
    "C_inter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "         [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "         [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "         [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "         [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "         [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]],\n",
       "\n",
       "        [[3.2407, 2.1343, 2.0139, 2.4896, 2.4506, 2.1681],\n",
       "         [2.1343, 2.7848, 2.1197, 2.4541, 2.7069, 1.9432],\n",
       "         [2.0139, 2.1197, 2.5502, 2.4861, 2.6303, 2.1749],\n",
       "         [2.4896, 2.4541, 2.4861, 4.1754, 3.1889, 2.8183],\n",
       "         [2.4506, 2.7069, 2.6303, 3.1889, 3.7358, 2.4337],\n",
       "         [2.1681, 1.9432, 2.1749, 2.8183, 2.4337, 2.9787]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the general formulation:\n",
    "batch_shape = C_inter_b.shape[:-4]\n",
    "C_inter_b.permute(*range(len(batch_shape)), -4, -2, -3, -1).reshape(*batch_shape, m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we go back? I.e. construct C_inter efficiently form the full matrix? Just do the same thing in reverse\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_inter_b_recov = A_b.reshape(*batch_shape, n, m, n, m).permute(*range(len(batch_shape)), -4, -2, -3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(C_inter_b, C_inter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-interleaved: block matrix where each block is an intra-task, cross-point covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_noninter = torch.zeros(m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for i in range(m):\n",
    "    for i_ in range(m):\n",
    "        for j in range(n):\n",
    "            for j_ in range(n):\n",
    "                C_noninter[i, i_, j, j_] = A[i*n+j, i_*n+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "        [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "        [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "        [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "        [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "        [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "        [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "        [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "        [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "        [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "        [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again we can construct the matrix as follows:\n",
    "C_noninter.permute(0, 2, 1, 3).reshape(m*n, m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batched version\n",
    "C_noninter_b = torch.zeros(b, m, m, n, n)\n",
    "\n",
    "# this is obviously super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(m):\n",
    "        for i_ in range(m):\n",
    "            for j in range(n):\n",
    "                for j_ in range(n):\n",
    "                    C_noninter_b[b_, i, i_, j, j_] = A_b[b_, i*n+j, i_*n+j_]\n",
    "                    \n",
    "torch.allclose(\n",
    "    C_noninter_b.permute(0, 1, 3, 2, 4).reshape(b, m*n, m*n),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and again we can go back the same way\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_noninter_b_recov = A_b.reshape(*batch_shape, m, n, m, n).permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_noninter_b, C_noninter_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternate mixed-interleaved: block matrix where each block is an intra-point, cross-task covariance\n",
    "\n",
    "This seems to be the most useful internal representation, as this means we don't have to do any permuting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate representation\n",
    "C_alt = torch.zeros(n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        for i_ in range(n):    \n",
    "            for j_ in range(m):\n",
    "                C_alt[i, j, i_, j_] = A[i*m+j, i_*m+j_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "        [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "        [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "        [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "        [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "        [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2407, 1.1343, 1.0139, 1.4896, 1.4506, 1.1681],\n",
       "        [1.1343, 1.7848, 1.1197, 1.4541, 1.7069, 0.9432],\n",
       "        [1.0139, 1.1197, 1.5502, 1.4861, 1.6303, 1.1749],\n",
       "        [1.4896, 1.4541, 1.4861, 3.1754, 2.1889, 1.8183],\n",
       "        [1.4506, 1.7069, 1.6303, 2.1889, 2.7358, 1.4337],\n",
       "        [1.1681, 0.9432, 1.1749, 1.8183, 1.4337, 1.9787]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is super straightforward\n",
    "C_alt.view(n*m, n*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternate representation\n",
    "C_alt_b = torch.zeros(b, n, m, n, m)\n",
    "\n",
    "# this is (obciously) super inefficient, but it makes clear what we want\n",
    "for b_ in range(b):\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            for i_ in range(n):    \n",
    "                for j_ in range(m):\n",
    "                    C_alt_b[b_, i, j, i_, j_] = A_b[b_, i*m+j, i_*m+j_]\n",
    "\n",
    "batch_shape = C_alt_b.shape[:-4]\n",
    "torch.allclose(\n",
    "    C_alt_b.view(*batch_shape, n*m, n*m),\n",
    "    A_b,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ....and going back\n",
    "\n",
    "batch_shape = A_b.shape[:-2]\n",
    "C_alt_b_recov = A_b.reshape(*batch_shape, n, m, n, m) #.permute(*range(len(batch_shape)), -4, -2, -3, -1)\n",
    "torch.allclose(C_alt_b, C_alt_b_recov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What if the tensor memory layout is different? Do we need to handle that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalarizing\n",
    "\n",
    "This representation makes scalarizing across the outputs trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7039, 1.0163, 1.2945],\n",
       "        [1.0163, 1.4423, 1.4991],\n",
       "        [1.2945, 1.4991, 2.0874]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(m)\n",
    "(C_alt @ weights).transpose(-1, -2) @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7039)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((C_alt[0, :, 0, :] @ weights) * weights).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4991)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((C_alt[1, :, 2, :] @ weights) * weights).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing outputs is also easy\n",
    "\n",
    "(straightforward to do this with more than one elements of the outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7848, 1.4541, 0.9432],\n",
       "        [1.4541, 3.1754, 1.8183],\n",
       "        [0.9432, 1.8183, 1.9787]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_alt[:, 1, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we can have MTMVN themselves be indexable - if we have the external API assume that the shape is `batch_shape x n x m`, then doing `mtmvn[:4, :]` would access all outputs of the first four data points. Similarly, `mtmvn[0, ..., 2:]` would extract the mtmvn across all datapoints of the first batch element for all but the first outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.distributions import MultivariateNormal, MultitaskMultivariateNormal\n",
    "mean = torch.rand(4)\n",
    "covar = torch.eye(4)\n",
    "mvn = MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn[-1].covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn[1:4].covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean should be a matrix or a batch matrix (batch mode)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-df1580eb1f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmtcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmtmvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultitaskMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtcovar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmtmvn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/gpytorch/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mnew_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/gpytorch/gpytorch/distributions/multitask_multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mean, covariance_matrix, validate_args, interleaved)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean should be a matrix or a batch matrix (batch mode)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean should be a matrix or a batch matrix (batch mode)"
     ]
    }
   ],
   "source": [
    "mtmean = torch.rand(4, 2)\n",
    "mtcovar = torch.eye(mtmean.numel())\n",
    "mtmvn = MultitaskMultivariateNormal(mtmean, mtcovar)\n",
    "mtmvn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing independet outputs\n",
    "\n",
    "Here we can just store the `m` individual `n x n` blocks as a `m x n x n` tensor, no need to store the cross covariances.\n",
    "\n",
    "We could also think of the case where we have independence across points, and only inter-task correlation. This will typically not be the case though, so we can punt on this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9865, 1.0179, 0.7360, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0179, 0.9832, 0.3909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7360, 0.3909, 1.0778, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 1.8661, 1.1281, 0.8259],\n",
       "        [0.0000, 0.0000, 0.0000, 1.1281, 1.9154, 0.5993],\n",
       "        [0.0000, 0.0000, 0.0000, 0.8259, 0.5993, 1.0213]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpytorch.lazy import BlockDiagLazyTensor\n",
    "\n",
    "C_indep = torch.stack([make_rand_covar(n) for _ in range(m)])\n",
    "\n",
    "# using the lazy here will speed up matrix operations\n",
    "BlockDiagLazyTensor(C_indep).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9865, 1.0179, 0.7360],\n",
       "         [1.0179, 0.9832, 0.3909],\n",
       "         [0.7360, 0.3909, 1.0778]],\n",
       "\n",
       "        [[1.8661, 1.1281, 0.8259],\n",
       "         [1.1281, 1.9154, 0.5993],\n",
       "         [0.8259, 0.5993, 1.0213]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9865, 1.0179, 0.7360, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0179, 0.9832, 0.3909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7360, 0.3909, 1.0778, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 1.8661, 1.1281, 0.8259],\n",
       "        [0.0000, 0.0000, 0.0000, 1.1281, 1.9154, 0.5993],\n",
       "        [0.0000, 0.0000, 0.0000, 0.8259, 0.5993, 1.0213]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we construct the full matrix (we don't want to do this in general, but maybe sometimes)\n",
    "# Once https://github.com/pytorch/pytorch/issues/31932 goes in, we can just use that instead\n",
    "\n",
    "batch_shape = C_indep.shape[:-3]\n",
    "out = torch.zeros(*batch_shape, m*n, m*n, device=C_indep.device, dtype=C_indep.dtype)\n",
    "for i, vals in enumerate(C_indep):\n",
    "    start = i*n\n",
    "    end = start + n\n",
    "    out[..., start:end, start:end].copy_(vals)\n",
    "    \n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also allow arbitrary order in the construction...\n",
    "\n",
    "### ... so long as we have a consistent internal representation\n",
    "\n",
    "The following orders are admissible (`n` is the number of points, `t` is the number tasks):\n",
    "\n",
    "```\n",
    "nntt\n",
    "ntnt\n",
    "nttn\n",
    "ttnn\n",
    "tntn\n",
    "tnnt\n",
    "\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "So basically we have the set \n",
    "```\n",
    "nnt\n",
    "ntt\n",
    "ntn\n",
    "ttn\n",
    "tnt\n",
    "tnn\n",
    "```\n",
    "\n",
    "and then the whole set of admissible combinations we get by combining this wiht the set we get by post-pending with the single letter (we could pre-pend too but that would just generate duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know this is admissible. We'd like to store things consistently internally. There are four options:\n",
    "\n",
    "- no independence -> can standardize to `n x t x n x t`\n",
    "- cross-task independence only -> can standardize to `t x n x n`\n",
    "- cross-point independence only -> can standardize to `n x t x t`\n",
    "- cross-task AND cross-point independence: This is trivial -> can standardize to `n x t` (just marginal variances)\n",
    "\n",
    "**For now we focus on the first two cases**, we can deal with the other ones later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpytorch.distributions.new_multitask_multivariate_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e28e3ce0b721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_multitask_multivariate_normal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultitaskMultivariateNormal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpytorch.distributions.new_multitask_multivariate_normal'"
     ]
    }
   ],
   "source": [
    "from gpytorch.distributions.new_multitask_multivariate_normal import MultitaskMultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_b = torch.randn(b, n, m)\n",
    "\n",
    "mtmvn = MultitaskMultivariateNormal(mean=mean_b, covariance=C_alt_b, order=(\"n\" ,\"t\", \"n\", \"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.1266, -28.4039])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn.log_prob(mtmvn.mean + torch.randn_like(mtmvn.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_indep_b = torch.stack([C_indep, C_indep + 1])\n",
    "\n",
    "mtmvn_indep = MultitaskMultivariateNormal(mean=mean_b, covariance=C_indep_b, order=(\"t\", \"n\", \"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.rsample(torch.Size([4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -7.5314, -11.0381])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtmvn_indep.log_prob(mtmvn_indep.mean + torch.randn_like(mtmvn_indep.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronecker product structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.lazy import KroneckerProductLazyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = torch.Size([2])\n",
    "\n",
    "Kn = make_rand_covar(n, batch_shape)\n",
    "Km = make_rand_covar(m, batch_shape)\n",
    "\n",
    "covar = KroneckerProductLazyTensor(Km, Kn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2282, 0.2174, 0.5029],\n",
       "         [0.2174, 0.8848, 0.4578],\n",
       "         [0.5029, 0.4578, 1.3140]],\n",
       "\n",
       "        [[2.1553, 1.2025, 0.7948],\n",
       "         [1.2025, 1.7784, 0.6121],\n",
       "         [0.7948, 0.6121, 1.5613]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5423, 0.1257],\n",
       "         [0.1257, 0.9608]],\n",
       "\n",
       "        [[0.8937, 0.7911],\n",
       "         [0.7911, 2.2355]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6661, 0.1179, 0.2727, 0.1544, 0.0273, 0.0632],\n",
       "         [0.1179, 0.4798, 0.2483, 0.0273, 0.1113, 0.0576],\n",
       "         [0.2727, 0.2483, 0.7125, 0.0632, 0.0576, 0.1652],\n",
       "         [0.1544, 0.0273, 0.0632, 1.1801, 0.2089, 0.4832],\n",
       "         [0.0273, 0.1113, 0.0576, 0.2089, 0.8501, 0.4399],\n",
       "         [0.0632, 0.0576, 0.1652, 0.4832, 0.4399, 1.2624]],\n",
       "\n",
       "        [[1.9263, 1.0747, 0.7104, 1.7050, 0.9513, 0.6287],\n",
       "         [1.0747, 1.5894, 0.5471, 0.9513, 1.4068, 0.4842],\n",
       "         [0.7104, 0.5471, 1.3954, 0.6287, 0.4842, 1.2351],\n",
       "         [1.7050, 0.9513, 0.6287, 4.8183, 2.6882, 1.7768],\n",
       "         [0.9513, 1.4068, 0.4842, 2.6882, 3.9756, 1.3684],\n",
       "         [0.6287, 0.4842, 1.2351, 1.7768, 1.3684, 3.4904]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6661, 0.1179, 0.2727, 0.1544, 0.0273, 0.0632],\n",
       "         [0.1179, 0.4798, 0.2483, 0.0273, 0.1113, 0.0576],\n",
       "         [0.2727, 0.2483, 0.7125, 0.0632, 0.0576, 0.1652],\n",
       "         [0.1544, 0.0273, 0.0632, 1.1801, 0.2089, 0.4832],\n",
       "         [0.0273, 0.1113, 0.0576, 0.2089, 0.8501, 0.4399],\n",
       "         [0.0632, 0.0576, 0.1652, 0.4832, 0.4399, 1.2624]],\n",
       "\n",
       "        [[1.9263, 1.0747, 0.7104, 1.7050, 0.9513, 0.6287],\n",
       "         [1.0747, 1.5894, 0.5471, 0.9513, 1.4068, 0.4842],\n",
       "         [0.7104, 0.5471, 1.3954, 0.6287, 0.4842, 1.2351],\n",
       "         [1.7050, 0.9513, 0.6287, 4.8183, 2.6882, 1.7768],\n",
       "         [0.9513, 1.4068, 0.4842, 2.6882, 3.9756, 1.3684],\n",
       "         [0.6287, 0.4842, 1.2351, 1.7768, 1.3684, 3.4904]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can construct the full tensor from the kronecker product (we DON'T want to do this)\n",
    "\n",
    "Dense = Km.unsqueeze(-1).unsqueeze(-1) * Kn.unsqueeze(-3).unsqueeze(-3).expand(*Km.shape, *Kn.shape[-2:])\n",
    "Dense.permute(0, 1, 3, 2, 4).reshape(*Km.shape[:-2], m*n, m*n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpytorch.distributions.multioutput_multivariate_normal import MultioutputMultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = C_inter.shape[0], C_inter.shape[2]\n",
    "mean = torch.rand(n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "momvn = MultioutputMultivariateNormal(mean, C_inter, \"nnmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.9305])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.log_prob(torch.rand(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn._covar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NormalizedOrder.FULL: 'nmnm'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn._nlzd_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1760, -0.0507],\n",
       "         [-1.2688,  1.2880],\n",
       "         [ 0.0351,  0.1168]],\n",
       "\n",
       "        [[ 2.4282,  3.6193],\n",
       "         [ 3.2335,  2.6217],\n",
       "         [ 1.4828,  2.8011]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.sample(torch.Size([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn._covar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "msub = momvn[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9740, 0.5032]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1095, 2.7778]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub._covar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3864])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.log_prob(torch.rand(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "msub = momvn[:2, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5032],\n",
       "        [0.2452]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7778],\n",
       "        [2.8220]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msub.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9740, 0.5032],\n",
       "        [0.3761, 0.2452],\n",
       "        [0.1522, 0.1482]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momvn.mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
